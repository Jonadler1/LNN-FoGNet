# LNN-FoGNet
# LNN-FoGNet â€“ Liquid Neural Networks for Real-Time Freezing-of-Gait Detection

<div align="center">
<img src="https://img.shields.io/badge/python-3.9-blue" />
<img src="https://img.shields.io/badge/tensorflow-2.18-important" />
<img src="https://img.shields.io/badge/keras-3.6-important" />
<img src="https://img.shields.io/badge/license-MIT-green" />
</div>

## âœ¨ Project summary
Freezing-of-Gait (FoG) is one of the most disabling symptoms of Parkinsonâ€™s disease.  
**LNN-FoGNet** explores whether **Liquid Neural Networks (LNNs)**â€”recurrent models whose neurons adapt their own time-constantsâ€”can deliver **LSTM-grade accuracy** while remaining **smaller, faster, and more energy-efficient** for round-the-clock wearables.

* **Dataset**â€ƒ[Daphnet FoG](https://archive.ics.uci.edu/ml/datasets/daphnet+freezing+of+gait)  
* **Models compared**â€ƒLiquid Neural Network (LNN / LTC)  |  Long Short-Term Memory (LSTM)  |  Continuous-Time RNN (CTRNN).  
* **Key results**  
  * Mean F1 â‰ˆ 0.95 on 5-fold subject-wise CV.  
  * LNN converges in **â‰ˆÂ½ the epochs and 1/10th the training time** of LSTM.  
  * Inference latency per step is **tens-of-times faster** than LSTM on the same hardware.



---

## ðŸ—‚ï¸ Repository layout

â”œâ”€â”€ fog.py # Main training / evaluation script

â”œâ”€â”€ ltc_model.py # LNN / Liquid-Time-Constant cell

â”œâ”€â”€ ctrnn_model.py # CTRNN cell and helpers

â”œâ”€â”€ vis.py # Training & ROC/PR visualisations

â”œâ”€â”€ vis_fog_events.py # Optional: example rawâ€signal plots

â”œâ”€â”€ fog_data.zip # â‡£ Unzip to ./fog_data/ before training

â””â”€â”€ results/ # Created automatically

â”œâ”€â”€ fog/ # Metrics, pickles, CSVs

â””â”€â”€ figures/ # Plots generated by vis.py


 ---
 
 ## ðŸ“‹ Requirements

| Package | Tested version |
|---------|----------------|
| **Python** | 3.9.13 |
| **TensorFlow** / **Keras** | 2.18 / 3.6 |
| `numpy`, `scikit-learn`, `matplotlib` | recent |
| *Optional* | `seaborn`, `tqdm` |

> **GPU:** Any recent NVIDIA card with CUDA 11+ gives a big speed-up, but the code also runs on CPU.

### Quick install
```bash
git clone https://github.com/Jonadler1/LNN-FoGNet.git
cd LNN-FoGNet

# Optional: create an isolated env
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install core deps
pip install "tensorflow~=2.18" keras==3.6 numpy scikit-learn matplotlib seaborn tqdm
```

---

## ðŸ“¦ Dataset

Inside the repo root
**unzip fog_data.zip -d fog_data**

fog.py expects ./fog_data/ to contain the raw .txt files exactly as provided by Daphnet.

---

## ðŸš€ Training & evaluation

The fog.py driver covers the entire pipeline: normalization â†’ windowing (+ micro-segmentation) â†’ k-fold subject-wise CV â†’ metrics aggregation.

Train an LNN with 32 hidden units for 20 epochs, 5-fold CV
**python fog.py --model ltc --size 32 --epochs 20 --k 5**

Other options:

 **--model   lstm | ctrnn | ltc**
 
 **--size    hidden units (default 32)**
 
 **--epochs  max epochs   (default 50)**
 
 **--k       CV folds     (default 5)**

Outputs (per fold and averaged) are written to results/fog/.

---

## ðŸ“Š Visualisation

Generate publication-quality plots once training is complete:

**python vis.py**

Figures are saved under results/figures/.
**vis_fog_events.py** optionally displays raw sensor traces of FoG vs non-FoG windows.
