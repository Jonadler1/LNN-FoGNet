# LNN-FoGNet
# LNN-FoGNet – Liquid Neural Networks for Real-Time Freezing-of-Gait Detection

<div align="center">
<img src="https://img.shields.io/badge/python-3.9-blue" />
<img src="https://img.shields.io/badge/tensorflow-2.18-important" />
<img src="https://img.shields.io/badge/keras-3.6-important" />
<img src="https://img.shields.io/badge/license-MIT-green" />
</div>

## ✨ Project summary
Freezing-of-Gait (FoG) is one of the most disabling symptoms of Parkinson’s disease.  
**LNN-FoGNet** explores whether **Liquid Neural Networks (LNNs)**—recurrent models whose neurons adapt their own time-constants—can deliver **LSTM-grade accuracy** while remaining **smaller, faster, and more energy-efficient** for round-the-clock wearables.

* **Dataset** [Daphnet FoG](https://archive.ics.uci.edu/ml/datasets/daphnet+freezing+of+gait)  
* **Models compared** Liquid Neural Network (LNN / LTC)  |  Long Short-Term Memory (LSTM)  |  Continuous-Time RNN (CTRNN).  
* **Key results**  
  * Mean F1 ≈ 0.95 on 5-fold subject-wise CV.  
  * LNN converges in **≈½ the epochs and 1/10th the training time** of LSTM.  
  * Inference latency per step is **tens-of-times faster** than LSTM on the same hardware.



---

## 🗂️ Repository layout

├── fog.py # Main training / evaluation script

├── ltc_model.py # LNN / Liquid-Time-Constant cell

├── ctrnn_model.py # CTRNN cell and helpers

├── vis.py # Training & ROC/PR visualisations

├── vis_fog_events.py # Optional: example raw‐signal plots

├── fog_data.zip # ⇣ Unzip to ./fog_data/ before training

└── results/ # Created automatically

├── fog/ # Metrics, pickles, CSVs

└── figures/ # Plots generated by vis.py


 ---
 
 ## 📋 Requirements

| Package | Tested version |
|---------|----------------|
| **Python** | 3.9.13 |
| **TensorFlow** / **Keras** | 2.18 / 3.6 |
| `numpy`, `scikit-learn`, `matplotlib` | recent |
| *Optional* | `seaborn`, `tqdm` |

> **GPU:** Any recent NVIDIA card with CUDA 11+ gives a big speed-up, but the code also runs on CPU.

### Quick install
```bash
git clone https://github.com/Jonadler1/LNN-FoGNet.git
cd LNN-FoGNet

# Optional: create an isolated env
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install core deps
pip install "tensorflow~=2.18" keras==3.6 numpy scikit-learn matplotlib seaborn tqdm
```

---

## 📦 Dataset

Inside the repo root
**unzip fog_data.zip -d fog_data**

fog.py expects ./fog_data/ to contain the raw .txt files exactly as provided by Daphnet.

---

## 🚀 Training & evaluation

The fog.py driver covers the entire pipeline: normalization → windowing (+ micro-segmentation) → k-fold subject-wise CV → metrics aggregation.

Train an LNN with 32 hidden units for 20 epochs, 5-fold CV
**python fog.py --model ltc --size 32 --epochs 20 --k 5**

Other options:

 **--model   lstm | ctrnn | ltc**
 
 **--size    hidden units (default 32)**
 
 **--epochs  max epochs   (default 50)**
 
 **--k       CV folds     (default 5)**

Outputs (per fold and averaged) are written to results/fog/.

---

## 📊 Visualisation

Generate publication-quality plots once training is complete:

**python vis.py**

Figures are saved under results/figures/.
**vis_fog_events.py** optionally displays raw sensor traces of FoG vs non-FoG windows.
